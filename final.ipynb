{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "m.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1Jx8NYnKEdQ",
        "colab_type": "text"
      },
      "source": [
        "# <center><b> Rating Prediction of Zomato Restaurants<b> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PsfZdvqwUP3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "7fb95b5e-5227-49f4-bafb-2cd03f6591ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NMpYvsfRfbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b3f70be1-1d89-4f0b-cf06-fc2ee53f68d9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDFQMZrGVHQU",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zNxrP_rmZWTi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cf833b1e-9ed3-4359-a754-f8fb426db124"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I5JJkMx_AwfY",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "# Combining all the above stundents \n",
        "from tqdm import tqdm\n",
        "import re\n",
        "# tqdm is for printing the status bar\n",
        "word_counter = []\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def filterised_text(text):\n",
        "    preprocessed_text = []\n",
        "    for sentance in tqdm(text):\n",
        "        sentance = re.sub('[0-9]+', '', sentance)\n",
        "        sentance = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
        "        sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "        sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "        sentance = decontracted(sentance)\n",
        "        sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "        sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "        sentance = ' '.join(word.lower() for word in sentance.split() if len(word)>1 and word.lower() not in stopwords.words('english'))\n",
        "        sentance = re.sub(r\"rated\", \"\", sentance)\n",
        "        count = len(sentance.split())\n",
        "        word_counter.append(count)\n",
        "        preprocessed_text.append(sentance.strip())\n",
        "    return preprocessed_text\n",
        "\n",
        "\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6bDk631uI5K",
        "colab_type": "text"
      },
      "source": [
        "We have to define 2 functions - \n",
        "1. func_1 - It should take in raw data as input and returns the prediction for the input.\n",
        "2. func_2 - It should take in raw data as input and retunrs the performance metrics value ie. mean squared error ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFa4FR1uvnXk",
        "colab_type": "text"
      },
      "source": [
        "#### Function - 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_zkSsfhJ2XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_1(param):\n",
        "  a=votes_scalar.transform(param['votes'].values.reshape(-1, 1))\n",
        "  b=cost_scalar.transform(param['approx_cost(for two people)'].values.reshape(-1, 1))\n",
        "  c=vectorizer_location.transform(param['location'])\n",
        "  d=vectorizer_dish_liked.transform(param['dish_liked'])\n",
        "  e=number_of_cuisines_scalar.transform(param['number_of_cuisines'].values.reshape(-1, 1))\n",
        "  f=vectorizer_book_table.transform(param['book_table'])\n",
        "  cleaned_reviews = filterised_text(param['preprocessed_reviews'].astype(str).values)\n",
        "  param['cleaned_reviews']  = cleaned_reviews\n",
        "  param=param.drop(['preprocessed_reviews'],axis=1)\n",
        "  g=vectorizer_text.transform(param['cleaned_reviews'])\n",
        "  h=vectorizer_rest_type.transform(param['rest_type'])\n",
        "  i= vectorizer_online_order.transform(param['online_order'])\n",
        "  j=vectorizer_cuisines.transform(param['cuisines']) \n",
        "  k=vectorizer_listed_in_tp.transform(param['listed_in(type)'])\n",
        "  l=vectorizer_listed_in_ct.transform(param['listed_in(city)'])\n",
        "  m=dish_liked_scalar.transform(param['mean_dish_liked'].values.reshape(-1, 1))\n",
        "  n=mean_cuisines_scalar.transform(param['mean_cuisines'].values.reshape(-1, 1))\n",
        "  o=number_of_liked_dishes_scalar.transform(param['number_of_liked_dishes'].values.reshape(-1, 1))\n",
        "  p=Facilities_offered_scalar.transform(param['Facilities_offered'].values.reshape(-1, 1))\n",
        "  final=hstack((a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p))\n",
        "  x=rfm.predict(final)\n",
        "  return x"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlQ-hN4dPB5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_point=pd.DataFrame({'online_order':['Yes','No'],'book_table':['Yes','No'],'votes':[705,455],'location':['Mysore Road','Banashankari'],'rest_type':['Casual Dining','Cafe'],'cuisines':['North Indian South Indian Andhra Chinese','Cafe Chinese Continental Italian'],'approx_cost(for two people)':[800.0,400.0],'listed_in(type)':['Buffet','Cafes'],'listed_in(city)':['Banashankari','Banashankari'],'dish_liked':['Masala Dosa','Masala Dosa'],'number_of_cuisines':[4,4],'number_of_liked_dishes':[1,7],'Facilities_offered':[0,1],'mean_dish_liked':[3.69,3.55],'mean_cuisines':[3.60,3.55],'preprocessed_reviews':['hi this is kishan','this food is good']})"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkJD1wxD785S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b13e1466-135f-4f1a-b56e-5991578358dc"
      },
      "source": [
        "func_1(query_point)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 336.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.621, 3.65 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrhBZQtLvdHX",
        "colab_type": "text"
      },
      "source": [
        "#### Function - 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZGjMgkcQkPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_2(param,label):\n",
        "  a=votes_scalar.transform(param['votes'].values.reshape(-1, 1))\n",
        "  b=cost_scalar.transform(param['approx_cost(for two people)'].values.reshape(-1, 1))\n",
        "  c=vectorizer_location.transform(param['location'])\n",
        "  d=vectorizer_dish_liked.transform(param['dish_liked'])\n",
        "  e=number_of_cuisines_scalar.transform(param['number_of_cuisines'].values.reshape(-1, 1))\n",
        "  f=vectorizer_book_table.transform(param['book_table'])\n",
        "  cleaned_reviews = filterised_text(param['preprocessed_reviews'].astype(str).values)\n",
        "  param['cleaned_reviews']  = cleaned_reviews\n",
        "  param=param.drop(['preprocessed_reviews'],axis=1)\n",
        "  g=vectorizer_text.transform(param['cleaned_reviews'])\n",
        "  h=vectorizer_rest_type.transform(param['rest_type'])\n",
        "  i= vectorizer_online_order.transform(param['online_order'])\n",
        "  j=vectorizer_cuisines.transform(param['cuisines']) \n",
        "  k=vectorizer_listed_in_tp.transform(param['listed_in(type)'])\n",
        "  l=vectorizer_listed_in_ct.transform(param['listed_in(city)'])\n",
        "  m=dish_liked_scalar.transform(param['mean_dish_liked'].values.reshape(-1, 1))\n",
        "  n=mean_cuisines_scalar.transform(param['mean_cuisines'].values.reshape(-1, 1))\n",
        "  o=number_of_liked_dishes_scalar.transform(param['number_of_liked_dishes'].values.reshape(-1, 1))\n",
        "  p=Facilities_offered_scalar.transform(param['Facilities_offered'].values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "  final=hstack((a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p))\n",
        "  k = rfm.predict(final)\n",
        "  x = mean_squared_error(label, k)\n",
        "  return x"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PtWFBeuQ3D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc234071-8d34-4aee-d40b-6050f1b25abc"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "func_2(query_point,[3.7,3.4])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03437050000000058"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    }
  ]
}